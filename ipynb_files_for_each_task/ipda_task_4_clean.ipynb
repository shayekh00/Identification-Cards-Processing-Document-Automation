{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22906,"status":"ok","timestamp":1707337059708,"user":{"displayName":"Richard L","userId":"01739195207295655374"},"user_tz":-60},"id":"K1Yc5Gv3uAO-","outputId":"bf5d1b93-e1a2-4d69-d9ec-4912ae01cfbd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUnaFdqfuLoE"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import cv2 as cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lICFeyd4uM8U"},"outputs":[],"source":["# Defining meta-information for model\n","IMG_WIDTH = 512\n","IMG_HEIGHT = 512\n","interpolation_method = cv.INTER_LANCZOS4 # Reasoning: also lanczos here\n","\n","# Defining Paths\n","dirname = os.path.dirname(__file__)\n","base_path = os.path.join(dirname, 'correct_path_to_dataset/4_cleaning/4_cleaning/') # define the correct path\n","train_path = base_path + 'Train/'\n","test_path = base_path + 'Test/'\n","\n","train_ids_dir = os.path.join(train_path, 'Ids')\n","train_masks_dir = os.path.join(train_path, 'GroundTruth')\n","\n","train_ids_list = sorted(os.listdir(train_ids_dir))\n","train_masks_list = sorted(os.listdir(train_masks_dir))\n","\n","test_ids_dir = os.path.join(test_path, 'Ids')\n","test_masks_dir = os.path.join(test_path, 'GroundTruth')\n","\n","test_ids_list = sorted(os.listdir(test_ids_dir))\n","test_masks_list = sorted(os.listdir(test_masks_dir))\n","\n","\n","# Handle Training Data\n","train_images = []\n","train_masks = []\n","\n","for img_name, mask_name in zip(train_ids_list, train_masks_list):\n","    img_path = os.path.join(train_ids_dir, img_name)\n","    mask_path = os.path.join(train_masks_dir, mask_name)\n","\n","    # Load and preprocess images\n","    img = cv.imread(img_path)\n","    img = cv.resize(img,(IMG_WIDTH,IMG_HEIGHT),interpolation=interpolation_method)\n","    train_images.append(img)\n","\n","    # Load and preprocess masks (assuming they are grayscale)\n","    mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n","    mask = cv.resize(mask,(IMG_WIDTH,IMG_HEIGHT),interpolation=interpolation_method)\n","    train_masks.append(mask)\n","\n","# Convert lists to numpy arrays\n","train_images = np.array(train_images)\n","train_masks = np.array(train_masks)\n","\n","# Normalize pixel values if needed (e.g., scale to [0, 1]) (done in next code cell)\n","train_images = train_images / 255.0\n","train_masks = train_masks / 255.0\n","\n","\n","# Handle Testing Data\n","test_images = []\n","test_masks = []\n","\n","for img_name, mask_name in zip(test_ids_list, test_masks_list):\n","    img_path = os.path.join(test_ids_dir, img_name)\n","    mask_path = os.path.join(test_masks_dir, mask_name)\n","\n","    # Load and preprocess images\n","    img = cv.imread(img_path)\n","    img = cv.resize(img,(IMG_WIDTH,IMG_HEIGHT),interpolation=interpolation_method)\n","    test_images.append(img)\n","\n","    # Load and preprocess masks (assuming they are grayscale)\n","    mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n","    mask = cv.resize(mask,(IMG_WIDTH,IMG_HEIGHT),interpolation=interpolation_method)\n","    test_masks.append(mask)\n","\n","# Convert lists to numpy arrays\n","test_images = np.array(test_images)\n","test_masks = np.array(test_masks)\n","\n","# Normalize pixel values if needed (e.g., scale to [0, 1]) (done in next code cell)\n","test_images = test_images / 255.0\n","test_masks = test_masks / 255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KarBhZt4uUJe"},"outputs":[],"source":["# Defining our U-Net\n","IMG_CHANNELS = 3\n","\n","inputs = tf.keras.layers.Input((IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))\n","\n","# downsampling\n","c1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n","c1 = tf.keras.layers.Dropout(0.1)(c1)\n","c1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n","\n","c2 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","c2 = tf.keras.layers.Dropout(0.1)(c2)\n","c2 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n","\n","c3 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","c3 = tf.keras.layers.Dropout(0.2)(c3)\n","c3 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n","\n","c4 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","c4 = tf.keras.layers.Dropout(0.3)(c4)\n","c4 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n","\n","c5 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","c5 = tf.keras.layers.Dropout(0.3)(c5)\n","c5 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","\n","# upsampling\n","u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2))(c5)\n","u6 = tf.keras.layers.concatenate([u6, c4])\n","c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","c6 = tf.keras.layers.Dropout(0.2)(c6)\n","c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n","\n","u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2))(c6)\n","u7 = tf.keras.layers.concatenate([u7, c3])\n","c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","c7 = tf.keras.layers.Dropout(0.2)(c7)\n","c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n","\n","u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2))(c7)\n","u8 = tf.keras.layers.concatenate([u8, c2])\n","c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","c8 = tf.keras.layers.Dropout(0.1)(c8)\n","c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n","\n","u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2))(c8)\n","u9 = tf.keras.layers.concatenate([u9, c1])\n","c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","c9 = tf.keras.layers.Dropout(0.1)(c9)\n","c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n","\n","outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjdFCLP0ugw9"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e0oIdNfuhPA"},"outputs":[],"source":["# https://stackoverflow.com/questions/63952338/how-to-save-best-weights-and-best-model-using-keras\n","checkpoint = None\n","callbacks_list = None\n","checkpoint = tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/ipda/models/ipda_task_4_clean_best_weights.h5', monitor='val_binary_io_u', verbose=1, save_best_only=True,  mode='max')\n","callbacks_list = [checkpoint]\n","\n","# Why adam for optimizer? Generally good performance according to https://stackoverflow.com/questions/37214884/how-do-i-choose-an-optimizer-for-my-tensorflow-model and common use in practice according to lecture slides\n","# Why binary_focal_crossentropy for loss? We work with binary segmentation (imbalanced problem).\n","# Why accuracy for metrics? Imbalanced problem, so we add Recall to the mix insteadof just accuracy\n","model.compile(optimizer='adam', loss='binary_focal_crossentropy', metrics=['accuracy','Recall',tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)])\n","fitting_information = model.fit(train_images, train_masks, validation_split=0.2, epochs=100, batch_size=8,callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eDN7pv5uzNR"},"outputs":[],"source":["# Test model and print validation and test accuracies\n","model.load_weights('/content/drive/My Drive/ipda/models/ipda_task_4_clean_best_weights.h5')\n","test_loss, test_acc, test_recall, test_binary_io_u = model.evaluate(test_images, test_masks)\n","\n","print(f\"training loss: {fitting_information.history['loss'][-1]}, training accuracy: {fitting_information.history['accuracy'][-1]}, training recall: {fitting_information.history['recall'][-1]}, training binary_io_u: {fitting_information.history['binary_io_u'][-1]}\")\n","print(f\"validation loss: {fitting_information.history['val_loss'][-1]}, validation accuracy: {fitting_information.history['val_accuracy'][-1]}, validation recall: {fitting_information.history['val_recall'][-1]}, validation binary_io_u: {fitting_information.history['val_binary_io_u'][-1]}\")\n","print(f\"test loss: {test_loss}, test accuracy: {test_acc}, test recall: {test_recall}, test binary_io_u: {test_binary_io_u}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsXxxceSuz3k"},"outputs":[],"source":["# Save Model\n","model.save('/content/drive/My Drive/ipda/models/ipda_task_4_clean_2')\n","model_save_path = os.path.join(dirname,'models/ipda_task_4_clean_3')"]},{"cell_type":"markdown","metadata":{"id":"qFxpwZomfuzd"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U01xtKicfwMf"},"outputs":[],"source":["print(f\"type of test_images[0]: {type(test_images[0])}\")\n","print(f\"shape of test_images[0]: {test_images[0].shape}\")\n","img_task_4_resized = np.expand_dims(test_images[0],axis=0)\n","prediction = model.predict(img_task_4_resized)\n","print(f\"type of prediction: {type(prediction)}\")\n","print(f\"shape of prediction: {prediction.shape}\")\n","\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(60, 30))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(test_images[0])\n","plt.title('Image Resized for Task 1')\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(prediction[0],cmap='gray')\n","plt.title('Predicted Mask Task 2')\n","plt.axis('off')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM1HEQKrO5Tcg14v9w+C5cw","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
